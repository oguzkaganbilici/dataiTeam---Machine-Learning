{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f97c5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae83a2c",
   "metadata": {},
   "source": [
    "# Prepare The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a48bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20050 entries, 0 to 20049\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   _unit_id               20050 non-null  int64  \n",
      " 1   _golden                20050 non-null  bool   \n",
      " 2   _unit_state            20050 non-null  object \n",
      " 3   _trusted_judgments     20050 non-null  int64  \n",
      " 4   _last_judgment_at      20000 non-null  object \n",
      " 5   gender                 19953 non-null  object \n",
      " 6   gender:confidence      20024 non-null  float64\n",
      " 7   profile_yn             20050 non-null  object \n",
      " 8   profile_yn:confidence  20050 non-null  float64\n",
      " 9   created                20050 non-null  object \n",
      " 10  description            16306 non-null  object \n",
      " 11  fav_number             20050 non-null  int64  \n",
      " 12  gender_gold            50 non-null     object \n",
      " 13  link_color             20050 non-null  object \n",
      " 14  name                   20050 non-null  object \n",
      " 15  profile_yn_gold        50 non-null     object \n",
      " 16  profileimage           20050 non-null  object \n",
      " 17  retweet_count          20050 non-null  int64  \n",
      " 18  sidebar_color          20050 non-null  object \n",
      " 19  text                   20050 non-null  object \n",
      " 20  tweet_coord            159 non-null    object \n",
      " 21  tweet_count            20050 non-null  int64  \n",
      " 22  tweet_created          20050 non-null  object \n",
      " 23  tweet_id               20050 non-null  float64\n",
      " 24  tweet_location         12565 non-null  object \n",
      " 25  user_timezone          12252 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(5), object(17)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"gender_classifier.csv\", encoding=\"latin1\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c509131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0    male                              i sing my own rhythm.\n",
       "1    male  I'm the author of novels filled with family dr...\n",
       "2    male                louis whining and squealing and all\n",
       "3    male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4  female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.concat([data.gender, data.description], axis=1)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec39685",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.dropna(axis = 0, inplace=True) # axis = 0 => satiri komple siler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79413afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt.gender = [1 if each == \"female\" else 0 for each in dt.gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10b497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "dt.gender = le.fit_transform(dt.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e81de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of gender\n",
      "1    5725\n",
      "2    5469\n",
      "0    4328\n",
      "3     702\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1 -> female\n",
      "2 -> male\n",
      "0 -> brand\n",
      "3 -> unknown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Distribution of {}\n",
    "\n",
    "1 -> female\n",
    "2 -> male\n",
    "0 -> brand\n",
    "3 -> unknown\n",
    "\"\"\".format(dt.gender.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a58e89",
   "metadata": {},
   "source": [
    "# Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62e6db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oguzk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oguzk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Regular Expression: includes a kind of search pattern algorithms\n",
    "import re\n",
    "\n",
    "## Stopwords \n",
    "# some words does not necessary to classify our text, such as the, to, as, and.\n",
    "# Because they do not show or include anything about owner\n",
    "import nltk #natural language tool kit\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "#Lemmatizer\n",
    "import nltk as nlp\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemma = nlp.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854e8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xx = []\n",
    "for i in dt.description:\n",
    "    editted = re.sub(\"[^a-zA-Z]\", \" \", i)\n",
    "    editted_ = editted.lower()\n",
    "    all_words = nltk.wordpunct_tokenize(editted_) # its better than split() method.\n",
    "    new_words = [lemma.lemmatize(each) for each in all_words if not each in set(stopwords.words(\"english\"))]\n",
    "    \n",
    "    xx.append(\" \".join(new_words))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00325593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>sing rhythm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>author novel filled family drama romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>louis whining squealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mobile guy er shazam google kleiner perkins ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ricky wilson best frontman kaiser chief best b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                        description\n",
       "0       2                                        sing rhythm\n",
       "1       2           author novel filled family drama romance\n",
       "2       2                            louis whining squealing\n",
       "3       2  mobile guy er shazam google kleiner perkins ya...\n",
       "4       1  ricky wilson best frontman kaiser chief best b..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.drop([\"description\"], axis=1, inplace=True)\n",
    "dt[\"description\"] = xx\n",
    "\n",
    "dt.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d266ed",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "It find a summarization of each unique words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "abf6de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #bag of words\n",
    "\n",
    "\n",
    "\n",
    "count_vectorizers = CountVectorizer(max_df=500, stop_words=\"english\")# it finds most 500 common words\n",
    "\n",
    "sparce_matrix = count_vectorizers.fit_transform(xx).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b9e7bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common 500 words: ['aa' 'aaa' 'aacc' ... 'zy' 'zyyfromyigo' 'zz']\n"
     ]
    }
   ],
   "source": [
    "print(\"The most common 500 words: {}\".format(count_vectorizers.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa77e7",
   "metadata": {},
   "source": [
    "# Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e7b56704",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.argmax(sparce_matrix, axis=1).reshape(-1,1)\n",
    "y = dt.gender.values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6e1db",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48ac8598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2532c5",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe578ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_head = nb.predict(x_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e4530",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "877f25a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bcfcf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model:  0.32409118915588414\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model: \",nb.score(y_head, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f832594",
   "metadata": {},
   "source": [
    "- do not forget. in this problem we have 4 genders. male, female, brand and unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7adafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
