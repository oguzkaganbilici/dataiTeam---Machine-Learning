{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70599990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04490a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca25182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"Unnamed: 32\",\"id\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e260260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis = [1 if each == \"M\" else 0 for each in df.diagnosis]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88441662",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.diagnosis.values\n",
    "\n",
    "x_data = df.drop([\"diagnosis\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614555e",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d601840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "T:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "T:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                  0.605518  ...      0.620776       0.141525   \n",
       "1                  0.141323  ...      0.606901       0.303571   \n",
       "2                  0.211247  ...      0.556386       0.360075   \n",
       "3                  1.000000  ...      0.248310       0.385928   \n",
       "4                  0.186816  ...      0.519744       0.123934   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                0.132056  ...      0.623266       0.383262   \n",
       "565                0.113100  ...      0.560655       0.699094   \n",
       "566                0.137321  ...      0.393099       0.589019   \n",
       "567                0.425442  ...      0.633582       0.730277   \n",
       "568                0.187026  ...      0.054287       0.489072   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           0.668310    0.450698          0.601136           0.619292   \n",
       "1           0.539818    0.435214          0.347553           0.154563   \n",
       "2           0.508442    0.374508          0.483590           0.385375   \n",
       "3           0.241347    0.094008          0.915472           0.814012   \n",
       "4           0.506948    0.341575          0.437364           0.172415   \n",
       "..               ...         ...               ...                ...   \n",
       "564         0.576174    0.452664          0.461137           0.178527   \n",
       "565         0.520892    0.379915          0.300007           0.159997   \n",
       "566         0.379949    0.230731          0.282177           0.273705   \n",
       "567         0.668310    0.402035          0.619626           0.815758   \n",
       "568         0.043578    0.020497          0.124084           0.036043   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.568610              0.912027        0.598462   \n",
       "1           0.192971              0.639175        0.233590   \n",
       "2           0.359744              0.835052        0.403706   \n",
       "3           0.548642              0.884880        1.000000   \n",
       "4           0.319489              0.558419        0.157500   \n",
       "..               ...                   ...             ...   \n",
       "564         0.328035              0.761512        0.097575   \n",
       "565         0.256789              0.559450        0.198502   \n",
       "566         0.271805              0.487285        0.128721   \n",
       "567         0.749760              0.910653        0.497142   \n",
       "568         0.000000              0.000000        0.257441   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                   0.418864  \n",
       "1                   0.222878  \n",
       "2                   0.213433  \n",
       "3                   0.773711  \n",
       "4                   0.142595  \n",
       "..                       ...  \n",
       "564                 0.105667  \n",
       "565                 0.074315  \n",
       "566                 0.151909  \n",
       "567                 0.452315  \n",
       "568                 0.100682  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data)).values\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289af8a6",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19598121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103fe473",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0c3184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (30, 455)\n",
      "x_test shape:  (30, 114)\n",
      "y_train shape:  (455,)\n",
      "y_test shape:  (114,)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878d48d",
   "metadata": {},
   "source": [
    "## Initializing the parameters and Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639d768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension, 1), 0.01) # dimension x 1 lik 0.01 lerden olusan matris olusturur\n",
    "    bias = 0.0\n",
    "    return w,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be3b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1 / (1 + np.exp(-z))\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5993245",
   "metadata": {},
   "source": [
    "## Implementing forward and backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113c2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b, x_train, y_train):\n",
    "    ## Forward\n",
    "    z = np.dot(w.T, x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1] # /455\n",
    "    \n",
    "    ## Backward\n",
    "    derivative_weight = (np.dot(x_train, ((y_head - y_train).T)))/x_train.shape[1]\n",
    "    derivative_bias = np.sum(y_head - y_train) / x_train.shape[1]\n",
    "    gradients = {\"Derivative weight\": derivative_weight, \"Derivative bias\": derivative_bias}\n",
    "    \n",
    "    return cost, gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e68b79",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbfbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate, number_of_iteration):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    # updating parameters is number_of_iteration times\n",
    "    for i in range(number_of_iteration):\n",
    "        cost, gradients = forward_backward_propagation(w,b, x_train, y_train)\n",
    "        cost_list.append(cost)\n",
    "        #update\n",
    "        w = w - learning_rate * gradients[\"Derivative weight\"]\n",
    "        b = b - learning_rate * gradients[\"Derivative bias\"]\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print(\"Cost after iteration %i: %f\" %(i,cost))\n",
    "            \n",
    "    # we learn the parameters weights and bias \n",
    "    parameters = {\"weight\": w, \"bias\": b}\n",
    "    plt.plot(index, cost_list2)\n",
    "    plt.xticks(index, rotation=\"vertical\")\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "        \n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7c731",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4bb248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w,b, x_test):\n",
    "    #x_test is an input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T, x_test) + b)\n",
    "    Y_prediction = np.zeros((1, x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, prediction is sign one (y_head = 1)\n",
    "    \n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0, i] <= 0.5:\n",
    "            Y_prediction[0, i] = 0\n",
    "        else:\n",
    "            Y_prediction[0, i] = 1\n",
    "            \n",
    "    return Y_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6f85db",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f8b4a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692977\n",
      "Cost after iteration 10: 0.662858\n",
      "Cost after iteration 20: 0.638204\n",
      "Cost after iteration 30: 0.616077\n",
      "Cost after iteration 40: 0.595774\n",
      "Cost after iteration 50: 0.577036\n",
      "Cost after iteration 60: 0.559699\n",
      "Cost after iteration 70: 0.543626\n",
      "Cost after iteration 80: 0.528696\n",
      "Cost after iteration 90: 0.514801\n",
      "Cost after iteration 100: 0.501845\n",
      "Cost after iteration 110: 0.489742\n",
      "Cost after iteration 120: 0.478412\n",
      "Cost after iteration 130: 0.467788\n",
      "Cost after iteration 140: 0.457807\n",
      "Cost after iteration 150: 0.448414\n",
      "Cost after iteration 160: 0.439560\n",
      "Cost after iteration 170: 0.431200\n",
      "Cost after iteration 180: 0.423295\n",
      "Cost after iteration 190: 0.415807\n",
      "Cost after iteration 200: 0.408706\n",
      "Cost after iteration 210: 0.401962\n",
      "Cost after iteration 220: 0.395548\n",
      "Cost after iteration 230: 0.389441\n",
      "Cost after iteration 240: 0.383619\n",
      "Cost after iteration 250: 0.378061\n",
      "Cost after iteration 260: 0.372751\n",
      "Cost after iteration 270: 0.367671\n",
      "Cost after iteration 280: 0.362807\n",
      "Cost after iteration 290: 0.358145\n",
      "Cost after iteration 300: 0.353672\n",
      "Cost after iteration 310: 0.349376\n",
      "Cost after iteration 320: 0.345247\n",
      "Cost after iteration 330: 0.341275\n",
      "Cost after iteration 340: 0.337452\n",
      "Cost after iteration 350: 0.333767\n",
      "Cost after iteration 360: 0.330215\n",
      "Cost after iteration 370: 0.326787\n",
      "Cost after iteration 380: 0.323476\n",
      "Cost after iteration 390: 0.320278\n",
      "Cost after iteration 400: 0.317185\n",
      "Cost after iteration 410: 0.314192\n",
      "Cost after iteration 420: 0.311295\n",
      "Cost after iteration 430: 0.308488\n",
      "Cost after iteration 440: 0.305767\n",
      "Cost after iteration 450: 0.303129\n",
      "Cost after iteration 460: 0.300568\n",
      "Cost after iteration 470: 0.298082\n",
      "Cost after iteration 480: 0.295668\n",
      "Cost after iteration 490: 0.293321\n",
      "Cost after iteration 500: 0.291040\n",
      "Cost after iteration 510: 0.288820\n",
      "Cost after iteration 520: 0.286660\n",
      "Cost after iteration 530: 0.284557\n",
      "Cost after iteration 540: 0.282509\n",
      "Cost after iteration 550: 0.280513\n",
      "Cost after iteration 560: 0.278567\n",
      "Cost after iteration 570: 0.276669\n",
      "Cost after iteration 580: 0.274817\n",
      "Cost after iteration 590: 0.273011\n",
      "Cost after iteration 600: 0.271246\n",
      "Cost after iteration 610: 0.269524\n",
      "Cost after iteration 620: 0.267840\n",
      "Cost after iteration 630: 0.266195\n",
      "Cost after iteration 640: 0.264587\n",
      "Cost after iteration 650: 0.263014\n",
      "Cost after iteration 660: 0.261475\n",
      "Cost after iteration 670: 0.259970\n",
      "Cost after iteration 680: 0.258496\n",
      "Cost after iteration 690: 0.257053\n",
      "Cost after iteration 700: 0.255640\n",
      "Cost after iteration 710: 0.254255\n",
      "Cost after iteration 720: 0.252899\n",
      "Cost after iteration 730: 0.251569\n",
      "Cost after iteration 740: 0.250265\n",
      "Cost after iteration 750: 0.248987\n",
      "Cost after iteration 760: 0.247732\n",
      "Cost after iteration 770: 0.246502\n",
      "Cost after iteration 780: 0.245294\n",
      "Cost after iteration 790: 0.244109\n",
      "Cost after iteration 800: 0.242945\n",
      "Cost after iteration 810: 0.241802\n",
      "Cost after iteration 820: 0.240679\n",
      "Cost after iteration 830: 0.239576\n",
      "Cost after iteration 840: 0.238492\n",
      "Cost after iteration 850: 0.237427\n",
      "Cost after iteration 860: 0.236380\n",
      "Cost after iteration 870: 0.235350\n",
      "Cost after iteration 880: 0.234337\n",
      "Cost after iteration 890: 0.233341\n",
      "Cost after iteration 900: 0.232361\n",
      "Cost after iteration 910: 0.231397\n",
      "Cost after iteration 920: 0.230448\n",
      "Cost after iteration 930: 0.229514\n",
      "Cost after iteration 940: 0.228595\n",
      "Cost after iteration 950: 0.227689\n",
      "Cost after iteration 960: 0.226798\n",
      "Cost after iteration 970: 0.225920\n",
      "Cost after iteration 980: 0.225055\n",
      "Cost after iteration 990: 0.224202\n",
      "Cost after iteration 1000: 0.223362\n",
      "Cost after iteration 1010: 0.222535\n",
      "Cost after iteration 1020: 0.221719\n",
      "Cost after iteration 1030: 0.220914\n",
      "Cost after iteration 1040: 0.220121\n",
      "Cost after iteration 1050: 0.219339\n",
      "Cost after iteration 1060: 0.218568\n",
      "Cost after iteration 1070: 0.217807\n",
      "Cost after iteration 1080: 0.217056\n",
      "Cost after iteration 1090: 0.216316\n",
      "Cost after iteration 1100: 0.215585\n",
      "Cost after iteration 1110: 0.214864\n",
      "Cost after iteration 1120: 0.214152\n",
      "Cost after iteration 1130: 0.213450\n",
      "Cost after iteration 1140: 0.212756\n",
      "Cost after iteration 1150: 0.212071\n",
      "Cost after iteration 1160: 0.211395\n",
      "Cost after iteration 1170: 0.210727\n",
      "Cost after iteration 1180: 0.210068\n",
      "Cost after iteration 1190: 0.209416\n",
      "Cost after iteration 1200: 0.208773\n",
      "Cost after iteration 1210: 0.208137\n",
      "Cost after iteration 1220: 0.207509\n",
      "Cost after iteration 1230: 0.206888\n",
      "Cost after iteration 1240: 0.206274\n",
      "Cost after iteration 1250: 0.205668\n",
      "Cost after iteration 1260: 0.205068\n",
      "Cost after iteration 1270: 0.204475\n",
      "Cost after iteration 1280: 0.203889\n",
      "Cost after iteration 1290: 0.203310\n",
      "Cost after iteration 1300: 0.202737\n",
      "Cost after iteration 1310: 0.202171\n",
      "Cost after iteration 1320: 0.201610\n",
      "Cost after iteration 1330: 0.201056\n",
      "Cost after iteration 1340: 0.200508\n",
      "Cost after iteration 1350: 0.199965\n",
      "Cost after iteration 1360: 0.199429\n",
      "Cost after iteration 1370: 0.198898\n",
      "Cost after iteration 1380: 0.198372\n",
      "Cost after iteration 1390: 0.197852\n",
      "Cost after iteration 1400: 0.197338\n",
      "Cost after iteration 1410: 0.196828\n",
      "Cost after iteration 1420: 0.196324\n",
      "Cost after iteration 1430: 0.195825\n",
      "Cost after iteration 1440: 0.195331\n",
      "Cost after iteration 1450: 0.194842\n",
      "Cost after iteration 1460: 0.194358\n",
      "Cost after iteration 1470: 0.193878\n",
      "Cost after iteration 1480: 0.193403\n",
      "Cost after iteration 1490: 0.192933\n",
      "Cost after iteration 1500: 0.192467\n",
      "Cost after iteration 1510: 0.192006\n",
      "Cost after iteration 1520: 0.191549\n",
      "Cost after iteration 1530: 0.191096\n",
      "Cost after iteration 1540: 0.190647\n",
      "Cost after iteration 1550: 0.190203\n",
      "Cost after iteration 1560: 0.189763\n",
      "Cost after iteration 1570: 0.189327\n",
      "Cost after iteration 1580: 0.188894\n",
      "Cost after iteration 1590: 0.188466\n",
      "Cost after iteration 1600: 0.188041\n",
      "Cost after iteration 1610: 0.187621\n",
      "Cost after iteration 1620: 0.187204\n",
      "Cost after iteration 1630: 0.186790\n",
      "Cost after iteration 1640: 0.186380\n",
      "Cost after iteration 1650: 0.185974\n",
      "Cost after iteration 1660: 0.185571\n",
      "Cost after iteration 1670: 0.185172\n",
      "Cost after iteration 1680: 0.184776\n",
      "Cost after iteration 1690: 0.184384\n",
      "Cost after iteration 1700: 0.183994\n",
      "Cost after iteration 1710: 0.183608\n",
      "Cost after iteration 1720: 0.183226\n",
      "Cost after iteration 1730: 0.182846\n",
      "Cost after iteration 1740: 0.182470\n",
      "Cost after iteration 1750: 0.182096\n",
      "Cost after iteration 1760: 0.181726\n",
      "Cost after iteration 1770: 0.181358\n",
      "Cost after iteration 1780: 0.180994\n",
      "Cost after iteration 1790: 0.180632\n",
      "Cost after iteration 1800: 0.180273\n",
      "Cost after iteration 1810: 0.179918\n",
      "Cost after iteration 1820: 0.179564\n",
      "Cost after iteration 1830: 0.179214\n",
      "Cost after iteration 1840: 0.178866\n",
      "Cost after iteration 1850: 0.178521\n",
      "Cost after iteration 1860: 0.178179\n",
      "Cost after iteration 1870: 0.177839\n",
      "Cost after iteration 1880: 0.177502\n",
      "Cost after iteration 1890: 0.177167\n",
      "Cost after iteration 1900: 0.176835\n",
      "Cost after iteration 1910: 0.176505\n",
      "Cost after iteration 1920: 0.176178\n",
      "Cost after iteration 1930: 0.175853\n",
      "Cost after iteration 1940: 0.175531\n",
      "Cost after iteration 1950: 0.175211\n",
      "Cost after iteration 1960: 0.174893\n",
      "Cost after iteration 1970: 0.174577\n",
      "Cost after iteration 1980: 0.174264\n",
      "Cost after iteration 1990: 0.173953\n",
      "Cost after iteration 2000: 0.173644\n",
      "Cost after iteration 2010: 0.173338\n",
      "Cost after iteration 2020: 0.173033\n",
      "Cost after iteration 2030: 0.172731\n",
      "Cost after iteration 2040: 0.172430\n",
      "Cost after iteration 2050: 0.172132\n",
      "Cost after iteration 2060: 0.171836\n",
      "Cost after iteration 2070: 0.171542\n",
      "Cost after iteration 2080: 0.171250\n",
      "Cost after iteration 2090: 0.170959\n",
      "Cost after iteration 2100: 0.170671\n",
      "Cost after iteration 2110: 0.170385\n",
      "Cost after iteration 2120: 0.170100\n",
      "Cost after iteration 2130: 0.169818\n",
      "Cost after iteration 2140: 0.169537\n",
      "Cost after iteration 2150: 0.169258\n",
      "Cost after iteration 2160: 0.168981\n",
      "Cost after iteration 2170: 0.168706\n",
      "Cost after iteration 2180: 0.168433\n",
      "Cost after iteration 2190: 0.168161\n",
      "Cost after iteration 2200: 0.167891\n",
      "Cost after iteration 2210: 0.167623\n",
      "Cost after iteration 2220: 0.167357\n",
      "Cost after iteration 2230: 0.167092\n",
      "Cost after iteration 2240: 0.166829\n",
      "Cost after iteration 2250: 0.166567\n",
      "Cost after iteration 2260: 0.166307\n",
      "Cost after iteration 2270: 0.166049\n",
      "Cost after iteration 2280: 0.165792\n",
      "Cost after iteration 2290: 0.165537\n",
      "Cost after iteration 2300: 0.165284\n",
      "Cost after iteration 2310: 0.165032\n",
      "Cost after iteration 2320: 0.164781\n",
      "Cost after iteration 2330: 0.164532\n",
      "Cost after iteration 2340: 0.164285\n",
      "Cost after iteration 2350: 0.164039\n",
      "Cost after iteration 2360: 0.163795\n",
      "Cost after iteration 2370: 0.163552\n",
      "Cost after iteration 2380: 0.163310\n",
      "Cost after iteration 2390: 0.163070\n",
      "Cost after iteration 2400: 0.162831\n",
      "Cost after iteration 2410: 0.162594\n",
      "Cost after iteration 2420: 0.162358\n",
      "Cost after iteration 2430: 0.162123\n",
      "Cost after iteration 2440: 0.161890\n",
      "Cost after iteration 2450: 0.161658\n",
      "Cost after iteration 2460: 0.161427\n",
      "Cost after iteration 2470: 0.161198\n",
      "Cost after iteration 2480: 0.160970\n",
      "Cost after iteration 2490: 0.160743\n",
      "Cost after iteration 2500: 0.160518\n",
      "Cost after iteration 2510: 0.160294\n",
      "Cost after iteration 2520: 0.160071\n",
      "Cost after iteration 2530: 0.159849\n",
      "Cost after iteration 2540: 0.159628\n",
      "Cost after iteration 2550: 0.159409\n",
      "Cost after iteration 2560: 0.159191\n",
      "Cost after iteration 2570: 0.158974\n",
      "Cost after iteration 2580: 0.158759\n",
      "Cost after iteration 2590: 0.158544\n",
      "Cost after iteration 2600: 0.158331\n",
      "Cost after iteration 2610: 0.158118\n",
      "Cost after iteration 2620: 0.157907\n",
      "Cost after iteration 2630: 0.157697\n",
      "Cost after iteration 2640: 0.157489\n",
      "Cost after iteration 2650: 0.157281\n",
      "Cost after iteration 2660: 0.157074\n",
      "Cost after iteration 2670: 0.156869\n",
      "Cost after iteration 2680: 0.156664\n",
      "Cost after iteration 2690: 0.156461\n",
      "Cost after iteration 2700: 0.156258\n",
      "Cost after iteration 2710: 0.156057\n",
      "Cost after iteration 2720: 0.155857\n",
      "Cost after iteration 2730: 0.155658\n",
      "Cost after iteration 2740: 0.155459\n",
      "Cost after iteration 2750: 0.155262\n",
      "Cost after iteration 2760: 0.155066\n",
      "Cost after iteration 2770: 0.154871\n",
      "Cost after iteration 2780: 0.154677\n",
      "Cost after iteration 2790: 0.154483\n",
      "Cost after iteration 2800: 0.154291\n",
      "Cost after iteration 2810: 0.154100\n",
      "Cost after iteration 2820: 0.153909\n",
      "Cost after iteration 2830: 0.153720\n",
      "Cost after iteration 2840: 0.153531\n",
      "Cost after iteration 2850: 0.153344\n",
      "Cost after iteration 2860: 0.153157\n",
      "Cost after iteration 2870: 0.152972\n",
      "Cost after iteration 2880: 0.152787\n",
      "Cost after iteration 2890: 0.152603\n",
      "Cost after iteration 2900: 0.152420\n",
      "Cost after iteration 2910: 0.152238\n",
      "Cost after iteration 2920: 0.152056\n",
      "Cost after iteration 2930: 0.151876\n",
      "Cost after iteration 2940: 0.151696\n",
      "Cost after iteration 2950: 0.151518\n",
      "Cost after iteration 2960: 0.151340\n",
      "Cost after iteration 2970: 0.151163\n",
      "Cost after iteration 2980: 0.150987\n",
      "Cost after iteration 2990: 0.150811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 96.49122807017544 % \n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate, num_it):\n",
    "    #initialize\n",
    "    dimension = x_train.shape[0] #30\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    \n",
    "     \n",
    "    parameters, gradients, cost_list = update(w,b,x_train, y_train, learning_rate, num_it)\n",
    "    \n",
    "    y_prediction_test = prediction(parameters[\"weight\"], parameters[\"bias\"], x_test)\n",
    "    \n",
    "    print(\"test accuracy: {} % \".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "\n",
    "logistic_regression(x_train, y_train, x_test, y_test, learning_rate=0.1, num_it=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433105a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
